

情景描述：

kafka集群三台，spark集群 stand-alone模式三台。

spark程序从kafka消费数据，发现挂掉一台kakfa机器后，就不能进行消费了。

诊断操作：

1.查看消费组的信息

结果： 发现根本就没有对应的消费组信息。（这个就不正常，虽然挂了一台broker，但是应该有消费组信息把，而且命令行消费其他topic消息没问题。换一个消费组重启程序也可以。）

从上面的发现，可以断定一个问题：spark程序没有问题，目前应该是kafka集群不正常。然而通过上面的操作也发现了一个点，挂掉一个特定broker后，消费组就没有了，可以肯定此消费组肯定和此broker绑定紧密。

那么问题来了？

问题一：为什么此消费组和挂掉的broker绑定紧密？

问题二：消费组信息是如何存储的？

接下来咱们就解析问题：

其实问题一和二差不多是一个问题，解答了问题二，问题一也就迎刃而解了。首先kakfa使用自身的 __consumer_offsets进行消费 offset信息的存储，二此topic默认是50个分区。而不同的消费组和 此 topic的关系：

```shell
# 也就是消费组的hash码和 consumer_offsets分区数 进行取余 操作,余数就是 consumer_offsets存储此消费组offset的分区
Math.abs(group.hashCode() % consumer_offsets.partitions)
```

通过计算，发现当前消费组取余操作后为11，计算格式如下：

```java
String str = "fm-standard-group";
int i = str.hashCode() % 50;
```

而挂掉的broker 就是存储 分区11的broker，还有一个重要问题是 分区的副本数为1，也就是分区11只在此broker上有，其他broker没有。

那到这里，问题就基本浮现了，因为存储消费组位移的consumer_offsets 分区11 对应的broker挂掉了，导致了拉取不到信息了。

故修复如下：

1、增加副本数，把 consumer_offsets 同步到其他机器，也就是挂调一台broker后，不影响继续拉取消费组消息.